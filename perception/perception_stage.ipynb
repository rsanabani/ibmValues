{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('perception_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    col: 'economic' if col.startswith('0 **Values Framework Pillar**') else\n",
    "        'functional' if col.startswith('1 **Values Framework Pillar**') else\n",
    "        'emotional' if col.startswith('2 **Values Framework Pillar**') else\n",
    "        'social' if col.startswith('3 **Values Framework Pillar**') else\n",
    "        'societal' if col.startswith('4 **Values Framework Pillar**') else\n",
    "        'original_tweets' if col.startswith('wsai_content_0') else\n",
    "        col\n",
    "    for col in df.columns\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\"value\": \"Economic\", \"entity\": \"Open AI\", \"perception\": 80},\\n  {\"value\": \"Economic\", \"entity\": \"Google\", \"perception\": 75},\\n  {\"value\": \"Economic\", \"entity\": \"Microsoft\", \"perception\": 82},\\n  {\"value\": \"Economic\", \"entity\": \"Meta\", \"perception\": 65},\\n  {\"value\": \"Economic\", \"entity\": \"IBM\", \"perception\": 70}\\n]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['economic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_author', 'original_tweets', 'Page_Rank', 'Rank', 'topic',\n",
       "       'author_display_name', 'bio', 'country', 'num_followers',\n",
       "       'Footprint_Influence_Score', 'economic', 'functional', 'emotional',\n",
       "       'social', 'societal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of columns to clean\n",
    "# value_columns = ['economic', 'functional', 'emotional', 'social', 'societal']\n",
    "\n",
    "# # Clean newlines and perform additional cleanup\n",
    "# for col in value_columns:\n",
    "#     # Remove newlines\n",
    "#     df[col] = df[col].str.replace('\\n', '')\n",
    "    \n",
    "#     # Remove any extra whitespace\n",
    "#     df[col] = df[col].str.strip()\n",
    "    \n",
    "#     # Remove empty strings and convert to NaN\n",
    "#     df[col] = df[col].replace('', pd.NA)\n",
    "    \n",
    "#     # Drop rows where all value columns are NaN\n",
    "#     df = df.dropna(subset=value_columns, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to clean\n",
    "value_columns = ['economic', 'functional', 'emotional', 'social', 'societal']\n",
    "\n",
    "# Clean newlines and perform additional cleanup\n",
    "for col in value_columns:\n",
    "    def clean_json_string(json_str):\n",
    "        try:\n",
    "            # Parse JSON string\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Perform any additional cleaning on the parsed data if necessary\n",
    "            # For example, ensure all entries have required fields\n",
    "            \n",
    "            # Convert back to JSON string\n",
    "            return json.dumps(data)\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle JSON parsing errors\n",
    "            return pd.NA\n",
    "    \n",
    "    # Apply cleaning function to each column\n",
    "    df[col] = df[col].apply(clean_json_string)\n",
    "    \n",
    "    # Drop rows where all value columns are NaN\n",
    "    df = df.dropna(subset=value_columns, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"value\": \"Economic\", \"entity\": \"Open AI\", \"perception\": 80}, {\"value\": \"Economic\", \"entity\": \"Google\", \"perception\": 75}, {\"value\": \"Economic\", \"entity\": \"Microsoft\", \"perception\": 82}, {\"value\": \"Economic\", \"entity\": \"Meta\", \"perception\": 65}, {\"value\": \"Economic\", \"entity\": \"IBM\", \"perception\": 70}]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['economic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses demand data by validating JSON structure and content.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input dataframe with columns [economic, functional, emotional, social, societal]\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (cleaned_df, malformed_df) where:\n",
    "            - cleaned_df contains only valid rows\n",
    "            - malformed_df contains rejected rows with reason for rejection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create copy of original dataframe\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Create list to store malformed rows and their reasons\n",
    "    malformed_rows = []\n",
    "    \n",
    "    def validate_json_array(json_str, row_idx, column):\n",
    "        try:\n",
    "            # Parse JSON string\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Check if it's a list with exactly 5 entries\n",
    "            if not isinstance(data, list) or len(data) != 5:\n",
    "                return False, f\"Invalid array length in {column}\"\n",
    "            \n",
    "            # Expected companies\n",
    "            expected_companies = {\"Open AI\", \"Google\", \"Microsoft\", \"Meta\", \"IBM\"}\n",
    "            \n",
    "            # Validate each entry\n",
    "            companies_found = set()\n",
    "            for entry in data:\n",
    "                # Check if entry has all required fields\n",
    "                if not all(key in entry for key in [\"value\", \"entity\", \"perception\"]):  # Updated field name\n",
    "                    return False, f\"Missing required fields in {column}\"\n",
    "                \n",
    "                # Check if perception is numeric\n",
    "                if not isinstance(entry[\"perception\"], (int, float)):  # Updated field name\n",
    "                    return False, f\"Invalid perception value in {column}\"\n",
    "                \n",
    "                # Check if entity is one of expected companies\n",
    "                if entry[\"entity\"] not in expected_companies:\n",
    "                    return False, f\"Invalid company name in {column}\"\n",
    "                \n",
    "                # Add company to found set\n",
    "                companies_found.add(entry[\"entity\"])\n",
    "            \n",
    "            # Check if all companies are present\n",
    "            if companies_found != expected_companies:\n",
    "                return False, f\"Missing companies in {column}\"\n",
    "            \n",
    "            return True, \"Valid\"\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            return False, f\"Invalid JSON format in {column}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Unexpected error in {column}: {str(e)}\"\n",
    "    \n",
    "    # Iterate through each row\n",
    "    for idx, row in df.iterrows():\n",
    "        row_valid = True\n",
    "        error_reasons = []\n",
    "        \n",
    "        # Check each column\n",
    "        for column in [\"economic\", \"functional\", \"emotional\", \"social\", \"societal\"]:\n",
    "            is_valid, reason = validate_json_array(row[column], idx, column)\n",
    "            if not is_valid:\n",
    "                row_valid = False\n",
    "                error_reasons.append(reason)\n",
    "        \n",
    "        # If row is not valid, add to malformed rows and mark for removal\n",
    "        if not row_valid:\n",
    "            malformed_rows.append({\n",
    "                \"row_index\": idx,\n",
    "                \"reasons\": \"; \".join(error_reasons),\n",
    "                **row\n",
    "            })\n",
    "            cleaned_df.drop(idx, inplace=True)\n",
    "    \n",
    "    # Create dataframe of malformed rows\n",
    "    malformed_df = pd.DataFrame(malformed_rows)\n",
    "    \n",
    "    # Reset index of cleaned dataframe\n",
    "    cleaned_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f\"Processed {len(df)} rows:\")\n",
    "    print(f\"- {len(cleaned_df)} valid rows\")\n",
    "    print(f\"- {len(malformed_df)} malformed rows\")\n",
    "    \n",
    "    return cleaned_df, malformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"value\": \"Economic\", \"entity\": \"Open AI\", \"perception\": 80}, {\"value\": \"Economic\", \"entity\": \"Google\", \"perception\": 75}, {\"value\": \"Economic\", \"entity\": \"Microsoft\", \"perception\": 82}, {\"value\": \"Economic\", \"entity\": \"Meta\", \"perception\": 65}, {\"value\": \"Economic\", \"entity\": \"IBM\", \"perception\": 70}]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['economic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see top 5 rows as df of just these rows 'economic', 'functional', 'emotional','social', 'societal'\n",
    "# df[['economic', 'functional', 'emotional','social', 'societal']].head()\n",
    "# save as csv\n",
    "# df[['economic', 'functional', 'emotional','social', 'societal']].to_csv('perception_processed_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 rows:\n",
      "- 297 valid rows\n",
      "- 3 malformed rows\n"
     ]
    }
   ],
   "source": [
    "cleaned_df, malformed_df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns we want\n",
    "metrics_columns = ['economic', 'functional', 'emotional', 'social', 'societal']\n",
    "cleaned_df[metrics_columns].to_csv('perception_processed_staged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
